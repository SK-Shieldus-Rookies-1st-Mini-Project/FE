import streamlit as st
import pymysql
import pandas as pd
from malicious_news import crawl_malicious_news
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns

# í•œê¸€í°íŠ¸ path ì„¤ì •
font_path = 'C:\\windows\\Fonts\\malgun.ttf'
font_prop = fm.FontProperties(fname=font_path).get_name()
matplotlib.rc('font', family=font_prop)

# DBì—ì„œ íŠ¹ì • URLì˜ ì•…ì„± ì—¬ë¶€ ì¡°íšŒ í•¨ìˆ˜
def get_url_result(url):
    try:
        conn = pymysql.connect(
            host='localhost',
            user='python',
            password='python',
            db='python_db',
            charset='utf8mb4'
        )
        with conn.cursor() as cursor:
            cursor.execute("SELECT result FROM test WHERE url = %s", (url,))
            row = cursor.fetchone()
            return row[0] if row else None
    except Exception as e:
        st.error(f"âŒ DB ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None
    finally:
        conn.close()

# DB ì „ì²´ ê¸°ë¡ ë¡œë“œ í•¨ìˆ˜ (í‘œì‹œìš©)
def load_from_DB():
    try:
        conn = pymysql.connect(
            host='localhost',
            user='python',
            password='python',
            db='python_db',
            charset='utf8mb4'
        )
        query = "SELECT url, url_len, url_entropy, result FROM test"
        df = pd.read_sql(query, conn)
        return df
    except Exception as e:
        st.error(f"âŒ ì „ì²´ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
        return pd.DataFrame()
    finally:
        conn.close()

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    st.set_page_config(page_title="ì˜¨ë¼ì¸ ë³´ì•ˆ ë‰´ìŠ¤", layout="wide")
    st.sidebar.title("ì§€í‚¤ë§ ë„¤ë¹„ê²Œì´ì…˜")
    page = st.sidebar.selectbox("í˜ì´ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ë©”ì¸", "ì˜¨ë¼ì¸ ë³´ì•ˆ ë‰´ìŠ¤"])

    if page == "ë©”ì¸":
        st.title("ì§€í‚¤ë§")
        st.write("ì›í•˜ëŠ” ê¸°ëŠ¥ì„ ë„¤ë¹„ê²Œì´ì…˜ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")

        # ê°€ìš´ë° ì…ë ¥ì°½
        left, center, right = st.columns([2, 4, 2])
        with center:
            user_url = st.text_input("ğŸ” ì•…ì„± ì—¬ë¶€ë¥¼ í™•ì¸í•  URLì„ ì…ë ¥í•˜ì„¸ìš”", "")
            if user_url:
                result = get_url_result(user_url)

                if result is None:
                    st.warning("ğŸ¤” ì´ URLì€ ì•„ì§ ë¶„ì„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                elif result == 1:
                    st.success(f"âœ… {user_url} ì‚¬ì´íŠ¸ëŠ” **ì •ìƒ ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤.**")
                elif result == -1:
                    st.error(f"ğŸš¨ {user_url} ì‚¬ì´íŠ¸ëŠ” **ì•…ì„± ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤.**")
                else:
                    st.info(f"âš ï¸ ë¶„ë¥˜ë˜ì§€ ì•Šì€ ê²°ê³¼ê°’: {result}")

                try:
                    st.markdown("### ğŸ§  í•´ë‹¹ URL ë¶„ì„ ì‹œê°í™”")
                    df = pd.read_csv('data/Feature Website2 HTML Processed.csv')

                    # ì‚¬ìš©ìê°€ ì…ë ¥í•œ urlê³¼ csv íŒŒì¼ì˜ 'url'ì»¬ëŸ¼ ê°’ê³¼ ì¼ì¹˜í•˜ëŠ” í–‰ë§Œ í•„í„°ë§, 
                    # csv íŒŒì¼ì˜ ì»¬ëŸ¼ ëª…ì— ë§ê²Œ ìˆ˜ì •
                    matched_row = df[df['url'] == user_url]

                    if not matched_row.empty:
                        # HTML íƒœê·¸ ê´€ë ¨ ì‹œê°í™”
                        html_columns = [col for col in df.columns if "html_num_tags" in col]
                        tag_counts = matched_row.iloc[0][html_columns]
                        tag_counts = tag_counts[tag_counts > 0]

                        if not tag_counts.empty:
                            fig1, ax1 = plt.subplots(figsize=(8, 8))
                            ax1.pie(tag_counts, labels=tag_counts.index.str.extract(r"\'(\w+)\'")[0], autopct='%1.1f%%')
                            ax1.set_title("HTML íƒœê·¸ ë¹„ìœ¨")
                            st.pyplot(fig1)
                        else:
                            st.info("í•´ë‹¹ URLì˜ HTML íƒœê·¸ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

                        # URL ê´€ë ¨ ì»¬ëŸ¼ ì‹œê°í™”
                        url_columns = [
                            'url_len', 'url_path_len', 'url_filename_len',
                            'url_domain_len', 'url_hostname_len', 'url_entropy',
                            'url_num_dots', 'url_num_slashes', 'url_num_equals'
                        ]

                        row_data = matched_row.iloc[0][url_columns].reset_index()
                        row_data.columns = ['Feature', 'Value']

                        fig2, ax2 = plt.subplots(figsize=(10, 6))
                        sns.barplot(data=row_data, x='Feature', y='Value', palette='Set2', ax=ax2)
                        ax2.set_xticklabels(ax2.get_xticklabels(), rotation=45)
                        ax2.set_title("URL ê´€ë ¨ ê°’ ë¹„êµ")
                        plt.tight_layout()
                        st.pyplot(fig2)
                    else:
                        st.info("âš ï¸ ì…ë ¥í•œ URLì— ëŒ€í•œ ìƒì„¸ ë°ì´í„°ê°€ CSV íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤.")


                except Exception as e:
                    st.warning(f"âš ï¸ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

        with center:
            # íŒë³„ ì´ë ¥ í…Œì´ë¸”
            st.subheader("ğŸ“Š URL íŒë³„ ì´ë ¥")
            df_history = load_from_DB()
            if not df_history.empty:
                df_history['result'] = df_history['result'].map({1: 'ì •ìƒ', -1: 'ì•…ì„±'}).fillna('ë¯¸ë¶„ë¥˜')
                st.dataframe(df_history)
            else:
                st.info("ì•„ì§ ì €ì¥ëœ URL ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
                

    elif page == "ì˜¨ë¼ì¸ ë³´ì•ˆ ë‰´ìŠ¤":
        st.title("ì˜¨ë¼ì¸ ë³´ì•ˆ ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤")
        st.write("ì‹¤ì‹œê°„ìœ¼ë¡œ ì˜¨ë¼ì¸ ë³´ì•ˆ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.")

        search_query = st.text_input("ë‰´ìŠ¤ ì œëª© ê²€ìƒ‰", "")
        with st.spinner('ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
            news = crawl_malicious_news()

        if news:
            filtered_news = [n for n in news if search_query.strip() == "" or search_query.lower() in n['title'].lower()]
            if not filtered_news:
                st.info("ê²€ìƒ‰ì–´ë¥¼ í¬í•¨í•˜ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            for n in filtered_news:
                with st.container():
                    cols = st.columns([1, 4])
                    with cols[0]:
                        if n['img']:
                            st.image(n['img'], width=80)
                    with cols[1]:
                        st.markdown(f"**{n['title']}**")
                        with st.expander("ë³¸ë¬¸ ë³´ê¸°"):
                            import requests
                            from bs4 import BeautifulSoup
                            try:
                                detail = requests.get(n['link'])
                                detail_soup = BeautifulSoup(detail.text, 'html.parser')
                                content = detail_soup.select_one('.con #con')
                                if content:
                                    html = str(content)
                                    st.markdown(f"<div style='margin-bottom:10px; line-height:1.7; font-size:10px !important;'>{html}</div>", unsafe_allow_html=True)
                                else:
                                    og_desc = detail_soup.find('meta', attrs={'property': 'og:description'})
                                    if og_desc and og_desc.get('content'):
                                        st.markdown(f"<div style='margin-bottom:10px; line-height:1.7; font-size:10px !important;'>{og_desc['content']}</div>", unsafe_allow_html=True)
                                    else:
                                        st.write('ë³¸ë¬¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                            except Exception:
                                st.write('ë³¸ë¬¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        else:
            st.info("ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
