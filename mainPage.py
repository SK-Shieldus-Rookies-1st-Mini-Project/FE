import streamlit as st
import pymysql
import pandas as pd
from malicious_news import crawl_malicious_news

# DBì—ì„œ íŠ¹ì • URLì˜ ì•…ì„± ì—¬ë¶€ ì¡°íšŒ í•¨ìˆ˜
def get_url_result(url):
    try:
        conn = pymysql.connect(
            host='localhost',
            user='python',
            password='python',
            db='python_db',
            charset='utf8mb4'
        )
        with conn.cursor() as cursor:
            cursor.execute("SELECT result FROM test WHERE url = %s", (url,))
            row = cursor.fetchone()
            return row[0] if row else None
    except Exception as e:
        st.error(f"âŒ DB ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None
    finally:
        conn.close()

# DB ì „ì²´ ê¸°ë¡ ë¡œë“œ í•¨ìˆ˜ (í‘œì‹œìš©)
def load_from_DB():
    try:
        conn = pymysql.connect(
            host='localhost',
            user='python',
            password='python',
            db='python_db',
            charset='utf8mb4'
        )
        query = "SELECT url, url_len, url_entropy, result FROM test"
        df = pd.read_sql(query, conn)
        return df
    except Exception as e:
        st.error(f"âŒ ì „ì²´ ë°ì´í„° ë¡œë”© ì˜¤ë¥˜: {e}")
        return pd.DataFrame()
    finally:
        conn.close()

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    st.set_page_config(page_title="ì˜¨ë¼ì¸ ë³´ì•ˆ ë‰´ìŠ¤", layout="wide")
    st.sidebar.title("ì§€í‚¤ë§ ë„¤ë¹„ê²Œì´ì…˜")
    page = st.sidebar.selectbox("í˜ì´ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”", ["ë©”ì¸", "ì˜¨ë¼ì¸ ë³´ì•ˆ ë‰´ìŠ¤"])

    if page == "ë©”ì¸":
        st.title("ì§€í‚¤ë§")
        st.write("ì›í•˜ëŠ” ê¸°ëŠ¥ì„ ë„¤ë¹„ê²Œì´ì…˜ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")

        # ê°€ìš´ë° ì…ë ¥ì°½
        left, center, right = st.columns([2, 4, 2])
        with center:
            user_url = st.text_input("ğŸ” ì•…ì„± ì—¬ë¶€ë¥¼ í™•ì¸í•  URLì„ ì…ë ¥í•˜ì„¸ìš”", "")
            if user_url:
                st.info(f"ì…ë ¥í•œ URL: {user_url}")
                result = get_url_result(user_url)

                if result is None:
                    st.warning("ğŸ¤” ì´ URLì€ ì•„ì§ ë¶„ì„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                elif result == 1:
                    st.success(f"âœ… {user_url} ì‚¬ì´íŠ¸ëŠ” **ì •ìƒ ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤.**")
                elif result == -1:
                    st.error(f"ğŸš¨ {user_url} ì‚¬ì´íŠ¸ëŠ” **ì•…ì„± ì‚¬ì´íŠ¸ì…ë‹ˆë‹¤.**")
                else:
                    st.info(f"âš ï¸ ë¶„ë¥˜ë˜ì§€ ì•Šì€ ê²°ê³¼ê°’: {result}")

        # íŒë³„ ì´ë ¥ í…Œì´ë¸”
        st.subheader("ğŸ“Š URL íŒë³„ ì´ë ¥")
        df_history = load_from_DB()
        if not df_history.empty:
            df_history['result'] = df_history['result'].map({1: 'ì •ìƒ', -1: 'ì•…ì„±'}).fillna('ë¯¸ë¶„ë¥˜')
            st.dataframe(df_history)
        else:
            st.info("ì•„ì§ ì €ì¥ëœ URL ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    elif page == "ì˜¨ë¼ì¸ ë³´ì•ˆ ë‰´ìŠ¤":
        st.title("ì˜¨ë¼ì¸ ë³´ì•ˆ ê´€ë ¨ ìµœì‹  ë‰´ìŠ¤")
        st.write("ì‹¤ì‹œê°„ìœ¼ë¡œ ì˜¨ë¼ì¸ ë³´ì•ˆ ê´€ë ¨ ë‰´ìŠ¤ë¥¼ í¬ë¡¤ë§í•˜ì—¬ ì œê³µí•©ë‹ˆë‹¤.")

        search_query = st.text_input("ë‰´ìŠ¤ ì œëª© ê²€ìƒ‰", "")
        with st.spinner('ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ì…ë‹ˆë‹¤...'):
            news = crawl_malicious_news()

        if news:
            filtered_news = [n for n in news if search_query.strip() == "" or search_query.lower() in n['title'].lower()]
            if not filtered_news:
                st.info("ê²€ìƒ‰ì–´ë¥¼ í¬í•¨í•˜ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            for n in filtered_news:
                with st.container():
                    cols = st.columns([1, 4])
                    with cols[0]:
                        if n['img']:
                            st.image(n['img'], width=80)
                    with cols[1]:
                        st.markdown(f"**{n['title']}**")
                        with st.expander("ë³¸ë¬¸ ë³´ê¸°"):
                            import requests
                            from bs4 import BeautifulSoup
                            try:
                                detail = requests.get(n['link'])
                                detail_soup = BeautifulSoup(detail.text, 'html.parser')
                                content = detail_soup.select_one('.con #con')
                                if content:
                                    html = str(content)
                                    st.markdown(f"<div style='margin-bottom:10px; line-height:1.7; font-size:10px !important;'>{html}</div>", unsafe_allow_html=True)
                                else:
                                    og_desc = detail_soup.find('meta', attrs={'property': 'og:description'})
                                    if og_desc and og_desc.get('content'):
                                        st.markdown(f"<div style='margin-bottom:10px; line-height:1.7; font-size:10px !important;'>{og_desc['content']}</div>", unsafe_allow_html=True)
                                    else:
                                        st.write('ë³¸ë¬¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                            except Exception:
                                st.write('ë³¸ë¬¸ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
        else:
            st.info("ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
